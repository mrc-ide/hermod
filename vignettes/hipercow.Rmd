---
title: "hipercow"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{hipercow}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---



<!-- Please edit the file in vignettes_src/ -->

Parallel computing on a cluster can be more challenging than running things locally because it's often the first time that you need to package up code to run elsewhere, and when things go wrong it's more difficult to get information on why things failed.

Much of the difficulty of getting things running involves working out what your code depends on, and getting that installed in the right place on a computer that you can't physically poke at.  The next set of problems is dealing with the ballooning set of files that end up being created - templates, scripts, output files, etc.

The `hipercow` package aims to remove some of this pain, with the aim that running a task on the cluster should be (almost) as straightforward as running things locally, at least once some basic setup is done.

At the moment, this document assumes that we will be using the "windows" cluster, which implies the existence of some future non-windows cluster. Stay tuned.

This manual is structured in escalating complexity, following the chain of things that a hypothetical user might encounter as they move from their first steps on the cluster through to running enormous batches of tasks.

# Installing prerequisites

Install the required packages from our "r-universe". Be sure to run this in a fresh session.

```r
install.packages(
  "hipercow",
  repos = c("https://mrc-ide.r-universe.dev", "https://cloud.r-project.org"))
```

Once installed you can load the package with


```r
library(hipercow)
```

or use the package by prefixing the calls below with `hipercow::`, as you prefer.

# Authentication with DIDE

First run the `windows_authenticate()` function which will talk you through entering your credentials and checking that they work. You only need to do this *once per machine, each time you change your password*.

A typical interaction with this looks like:

```
> windows_authenticate()
I need to unlock the system keychain in order to load and save
your credentials.  This might differ from your DIDE password,
and will be the password you use to log in to this particular
machine
Keyring password:
ðŸ”‘  OK

â”€â”€ Please enter your DIDE credentials â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
We need to know your DIDE username and password in order to log
you into the cluster. This will be shared across all projects
on this machine, with the username and password stored securely
in your system keychain. You will have to run this command
again on other computers

Your DIDE password may differ from your Imperial password, and
in some cases your username may also differ. If in doubt,
perhaps try logging in at https://mrcdata.dide.ic.ac.uk/hpc and
use the combination that works for you there.

DIDE username (default: rfitzjoh) >
Password:
ðŸ”‘  OK

I am going to try and log in with your password now, if this
fails we can always try again, as failure is just the first
step towards great success.
Excellent news! Everything seems to work!
```

# Filesystems and paths

We need a concept of a "root"; the point in the filesystem we can think of everything relative to.  This will feel familiar to you if you have used git or orderly, as these all have a root (and this root will be a fine place to put your cluster work). Typically all paths will be *within* this root directory, and paths above it, or absolute paths in general, effectively cease to exist. If your project works this way then it's easy to move around, which is exactly what we need to do in order to run it on the cluster.

The Windows cluster needs everything to be available on a filesystem
that the cluster can read.  Practically this means the filesystems
`//fi--didef3.dide.ic.ac.uk/tmp` or `//fi--san03.dide.ic.ac.uk/homes/username` and the like.
You probably have access to network shares that are specific to a
project, too.  For Windows users these are probably mapped to
drives (`Q:` or `T:` or similar) already, but for other platforms
you will need to do a little extra work to get things set up (see
below).

In general we **strongly recommend** that you use project shares for any serious work, rather than your home directory.  To organise these you should talk to your PI (or if you are a PI, talk to Chris).  The advantages of the project shares is that they are larger (so you will run out of disk space more slowly) and faster than the home shares.  If you launch many tasks at once that use your home share you can get unexpected failures as the disk can't keep up with amount of data being read and written.

*To set up your shares, or learn more, please see the "Paths and shares" section in `vignette("details")`.*

Set your working directory to be on the share with `setwd(...)` and then you can write:


```r
hipercow_init(driver = "windows")
#> âœ” Initialised hipercow at '.'
#> âœ” Configured hipercow to use 'windows'
```

which will write things to a new path `hipercow/` within your working directory and set you up to use the windows cluster, which is the only option at present.

By default, we aim to automatically detect your shares, and we believe this works on Windows, macOS and Linux.  If you are running on a network share and the configuration errors because it cannot work out what share you are on, please let us know.

You may need additional shares (e.g., to access large data accessed by absolute path).  See the section on shares in `vignette("details")` for more details.

You can see the computed configuration by running `hipercow_configuration()`:


```r
hipercow_configuration()
#> 
#> â”€â”€ hipercow root at /home/rfitzjoh/net/home/cluster/hipercow-vignette/hv-20240110-50ab6375fe865 â”€â”€â”€
#> âœ” Working directory '.' within root
#> â„¹ R version 4.3.1 on Linux (rfitzjoh@wpia-dide300)
#> 
#> â”€â”€ Packages â”€â”€
#> 
#> â„¹ This is hipercow 0.2.9
#> â„¹ Installed: hipercow.windows (0.2.9), conan2 (1.9.95), logwatch (0.1.0)
#> 
#> â”€â”€ Environments â”€â”€
#> 
#> â”€â”€ default
#> â€¢ packages: (none)
#> â€¢ sources: (none)
#> â€¢ globals: (none)
#> 
#> â”€â”€ Drivers â”€â”€
#> 
#> âœ” 1 driver configured ('windows')
#> 
#> â”€â”€ windows
#> â€¢ cluster: wpia-hn
#> â€¢ template: AllNodes
#> â€¢ shares: 1 configured:
#> â†’ (local) /home/rfitzjoh/net/home => \\fi--san03.dide.ic.ac.uk\homes\rfitzjoh => V: (remote)
#> â€¢ r_version: 4.3.0
#> â€¢ path_lib: hipercow/lib/windows/4.3.0
#> â€¢ username: rfitzjoh
```

# Running your first task

The first time you use the tools (ever, in a while, or on a new machine) we recommend sending off a tiny task to make sure that everything is working as expected:


```r
id <- task_create_expr(sessionInfo())
#> âœ” Submitted task '40d27cb021457a157b55c392c28e523a' using 'windows'
```

This creates a new task that will run on the cluster which will run the expression `sessionInfo()`. The `task_create_expr()` function works by so-called ["non standard evaluation"](https://adv-r.hadley.nz/metaprogramming.html) and the expression is not evaluated from your R session, but sent to run on another machine.

The `id` returned is just an ugly hex string:


```r
id
#> [1] "40d27cb021457a157b55c392c28e523a"
```



Many other functions accept this id as an argument.  You can get the status of the task, which will have finished now because it really does not take very long:


```r
task_status(id)
#> [1] "success"
```

Once the task has completed you can inspect the result:


```r
task_result(id)
#> R version 4.3.0 (2023-04-21 ucrt)
#> Platform: x86_64-w64-mingw32/x64 (64-bit)
#> Running under: Windows 10 x64 (build 19045)
#> 
#> Matrix products: default
#> 
#> 
#> locale:
#> [1] LC_COLLATE=English_United Kingdom.utf8 
#> [2] LC_CTYPE=English_United Kingdom.utf8   
#> [3] LC_MONETARY=English_United Kingdom.utf8
#> [4] LC_NUMERIC=C                           
#> [5] LC_TIME=English_United Kingdom.utf8    
#> 
#> time zone: Europe/London
#> tzcode source: internal
#> 
#> attached base packages:
#> [1] stats     graphics  grDevices utils     datasets  methods   base     
#> 
#> loaded via a namespace (and not attached):
#> [1] compiler_4.3.0  cli_3.6.2       rprojroot_2.0.4 withr_2.5.2    
#> [5] hipercow_0.2.9  rlang_1.1.2
```

You can see that this result is different from what we'd get by running `sessionInfo()` locally:


```r
sessionInfo()
#> R version 4.3.1 (2023-06-16)
#> Platform: x86_64-pc-linux-gnu (64-bit)
#> Running under: Ubuntu 20.04.6 LTS
#> 
#> Matrix products: default
#> BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 
#> LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3;  LAPACK version 3.9.0
#> 
#> locale:
#>  [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C              
#>  [3] LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8    
#>  [5] LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_GB.UTF-8   
#>  [7] LC_PAPER=en_GB.UTF-8       LC_NAME=C                 
#>  [9] LC_ADDRESS=C               LC_TELEPHONE=C            
#> [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C       
#> 
#> time zone: Europe/London
#> tzcode source: system (glibc)
#> 
#> attached base packages:
#> [1] stats     graphics  grDevices utils     datasets  methods   base     
#> 
#> other attached packages:
#> [1] hipercow_0.2.9  testthat_3.1.10
#> 
#> loaded via a namespace (and not attached):
#>  [1] vctrs_0.6.3            ids_1.0.1              httr_1.4.6            
#>  [4] cli_3.6.2              knitr_1.43             rlang_1.1.1           
#>  [7] xfun_0.39              pkgload_1.3.2.1        assertthat_0.2.1      
#> [10] jsonlite_1.8.7         glue_1.6.2             prettyunits_1.1.1     
#> [13] openssl_2.1.0          sodium_1.2.1           askpass_1.1           
#> [16] rprojroot_2.0.3        brio_1.1.3             fansi_1.0.4           
#> [19] rappdirs_0.3.3         logwatch_0.1.0         evaluate_0.21         
#> [22] tibble_3.2.1           filelock_1.0.2         yaml_2.3.7            
#> [25] lifecycle_1.0.3        compiler_4.3.1         rematch_1.0.1         
#> [28] fs_1.6.3               pkgconfig_2.0.3        keyring_1.3.1         
#> [31] R6_2.5.1               utf8_1.2.3             curl_5.0.1            
#> [34] pillar_1.9.0           magrittr_2.0.3         uuid_1.1-0            
#> [37] tools_4.3.1            withr_2.5.0            xml2_1.3.5            
#> [40] hipercow.windows_0.2.9 desc_1.4.2
```

# Using functions you have written

It's unlikely that the code you want to run on the cluster is one of the functions built into R itself; more likely you have written a simulation or similar and you want to run *that* instead.  In order to do this, we need to tell the cluster where to find your code. There are two broad places where code that you want to run is likely to be found **script files** and **packages**; we start with the former here, and deal with packages in much more detail in `vignette("packages")`.

Suppose you have a file `simulation.R` containing some simulation:

```r
random_walk <- function(x, n_steps) {
  ret <- numeric(n_steps)
  for (i in seq_len(n_steps)) {
    x <- rnorm(1, x)
    ret[[i]] <- x
  }
  ret
}
```

We can't run this on the cluster immediately, because it does not know where it comes from:


```r
id <- task_create_expr(random_walk(0, 10))
#> âœ” Submitted task '846ea49229ef98e8af262a3239257010' using 'windows'
task_wait(id)
#> [1] FALSE
task_result(id)
#> <simpleError in random_walk(0, 10): could not find function "random_walk">
```

(See `vignette("troubleshooting")` for more on failures.)

We need to tell hipercow to `source()` the file `simulation.R` before running the task. To do this we use `hipercow_environment_create()` to create an "environment" (not to be confused with R's environments) in which to run things:


```r
hipercow_environment_create(sources = "simulation.R")
#> âœ” Created environment 'default'
```

Now we can run our simulation:


```r
id <- task_create_expr(random_walk(0, 10))
#> âœ” Submitted task '92e3706bda0081a55dceb263792db3fe' using 'windows'
task_wait(id)
#> [1] TRUE
task_result(id)
#>  [1]  0.72266105 -0.42844302 -1.47597204 -1.75237061 -0.62806041 -0.03851776
#>  [7]  0.19192234 -0.90095973 -2.01881904 -1.19745107
```

# Getting information about tasks

Once you have created (and submitted) tasks, they will be queued by the cluster and eventually run.  The hope is that we surface enough information to make it easy for you to see how things are going and what has gone wrong.

## Fetching times with `task_info()`


```r
task_info(id)
#> 
#> â”€â”€ task 92e3706bda0081a55dceb263792db3fe (success) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#> â„¹ Submitted with 'windows'
#> â„¹ Created at 2024-01-10 10:33:13.059888 (moments ago)
#> â„¹ Started at 2024-01-10 10:33:13.789803 (moments ago; waited 730ms)
#> â„¹ Finished at 2024-01-10 10:33:14.213412 (moments ago; ran for 424ms)
```

This prints out information about the task; it's identifer (`92e3706bda0081a55dceb263792db3fe`) and status (`success`), along with the time that key events happened for the task (when it was created, started and finished). 

This display is meant to be friendly; if you need to compute on this information, you can access the times by reading the `$times` element of the `task_info()` return value:


```r
task_info(id)$times
#>                   created                   started                  finished 
#> "2024-01-10 10:33:13 GMT" "2024-01-10 10:33:13 GMT" "2024-01-10 10:33:14 GMT"
```

## Fetching logs with `task_log_show`

Every task will produce some logs, and these can be an important part of understanding what they did and why they went wrong.

You can view the log with `task_log_show()`


```r
task_log_show(id)
#> 
#> â”€â”€ hipercow 0.2.9 running at 'V:/cluster/hipercow-vignette/hv-20240110-50ab6375f
#> â„¹ library paths:
#> â€¢
#> V:/cluster/hipercow-vignette/hv-20240110-50ab6375fe865/hipercow/lib/windows/4.3.0
#> â€¢ I:/bootstrap-dev/4.3.0
#> â€¢ C:/Program Files/R/R-4.3.0/library
#> â„¹ id: 92e3706bda0081a55dceb263792db3fe
#> â„¹ starting at: 2024-01-10 10:33:13.789803
#> â„¹ task type: expression
#> â„¹ expression: random_walk(0, 10)
#> â„¹ no local variables
#> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ task logs â†“ â”€â”€
#> 
#> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ task logs â†‘ â”€â”€
#> âœ” status: success
#> â„¹ finishing at: 2024-01-10 10:33:13.789803 (elapsed: 0.4392 secs)
```

This prints the contents of the logs to the screen; you can access the values directly with `task_log_value(id)`.  The format of the logs will be generally the same for all tasks; after the header saying where we are running, some information about the task will be printed (its identifier, the time, details about the task itself), then any logs that come from calls to `message()` and `print()` within the queued function (within the "task logs" section; here that is empty because our task prints nothing).  Finally, a summary will be printed with the final status, final time (and elapsed time), then any warnings that were produced will be flushed (see `vignettes("troubleshooting")` for more on warnings).

There is a second log too, the "outer" log, which is generally less interesting so it is not the default.  These logs come from the cluster scheduler itself and show the startup process that leads up to (and after) the code that hipercow itself runs.  It will differ from driver to driver.  In addition, this log may not be available forever; the windows cluster retains it only for a couple of weeks:


```r
task_log_show(id, outer = TRUE)
#> generated on host: wpia-dide300
#> generated on date: 2024-01-10 10:33:13.070742
#> hipercow version: 0.2.9
#> running on: WPIA-017
#> The command completed successfully.
#> 
#> Using RTOOLS43_HOME = I:\Rtools\Rtools43
#> mapping V: -> \\fi--san03.dide.ic.ac.uk\homes\rfitzjoh
#> The command completed successfully.
#> 
#> working directory: V:\cluster\hipercow-vignette\hv-20240110-50ab6375fe865
#> this is a single task
#> 
#> V:\cluster\hipercow-vignette\hv-20240110-50ab6375fe865>Rscript -e "hipercow::task_eval('92e3706bda0081a55dceb263792db3fe', verbose = TRUE)"  1>"hipercow\tasks\92e3706bda0081a55dceb263792db3fe\log" 2>&1
#> Removing mapping V:
#> V: was deleted successfully.
#> 
#> I: was deleted successfully.
#> 
#> Quitting
```

## Watching logs with `task_log_watch`

If your task is still running, you can stream logs to your computer using `task_log_watch()`; this will print new logs line-by-line as they arrive (with a delay of up to 1s by default). This can be useful while debugging something to give the illusion that you're running it locally.

Using `Ctrl-C` (or `ESC`) to escape will only stop log streaming and not the underlying task.

# Understanding where variables come from

Suppose our simulation started not from 0, but from some point that we have computed locally (say `x`, imaginatively)


```r
x <- 100
```

You can use this value to start the simulation by running:


```r
id <- task_create_expr(random_walk(x, 10))
#> âœ” Submitted task '1f62af10a9a59fb4bb3a1578a6055ef2' using 'windows'
```

Here the `x` value has come from the environment where the expression passed into `task_create_expr()` was found (specifically, we use the [`rlang` "tidy evaluation"](https://rlang.r-lib.org/reference/topic-defuse.html) framework you might be familiar with from `dplyr` and friends).


```r
task_wait(id)
#> [1] TRUE
task_result(id)
#>  [1]  99.06522  98.87759  99.92704 101.00309 101.04280 102.94028 103.56928
#>  [8] 102.07917 102.78773 101.65776
```

If you pass in an expression that references a value that does not exist locally, you will get a (hopefully) informative error message when the task is created:


```r
id <- task_create_expr(random_walk(starting_point, 10))
#> Error in `rlang::env_get_list()` at hipercow/R/task-create.R:240:4:
#> ! Can't find `starting_point` in environment.
```

# Cancelling tasks

You can cancel a task if it has submitted and not completed, using `task_cancel`:

For example, here's a task that will sleep for 10 minutes, which we submit to the cluster:


```r
id <- task_create_expr(Sys.sleep(600))
#> âœ” Submitted task '66b355a95e9ac588030784270ce6b410' using 'windows'
```



This task is now running:


```r
task_status(id)
#> [1] "running"
task_info(id)
#> 
#> â”€â”€ task 66b355a95e9ac588030784270ce6b410 (running) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#> â„¹ Submitted with 'windows'
#> â„¹ Created at 2024-01-10 10:33:16.298285 (moments ago)
#> â„¹ Started at 2024-01-10 10:33:17.263568 (moments ago; waited 966ms)
#> ! Not finished yet (running for 933ms)
```

Having decided that this is a silly idea, we can cancel it:


```r
task_cancel(id)
#> âœ” Successfully cancelled '66b355a95e9ac588030784270ce6b410'
#> [1] TRUE
task_status(id)
#> [1] "cancelled"
task_info(id)
#> 
#> â”€â”€ task 66b355a95e9ac588030784270ce6b410 (cancelled) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#> â„¹ Submitted with 'windows'
#> â„¹ Created at 2024-01-10 10:33:16.298285 (moments ago)
#> â„¹ Started at 2024-01-10 10:33:17.263568 (moments ago; waited 966ms)
#> â„¹ Finished at 2024-01-10 10:33:19.762556 (moments ago; ran for 2.5s)
```

You can cancel a task that is submitted (waiting to be picked up by a cluster) or running.  You can cancel many tasks at once by passing a vector of identifiers through.

# Retrying tasks

There are lots of reasons why you might want to retry a task:

* it failed but you think it might work next time
* you updated a package that it used, and want to try again with the new version
* you don't like the output from some stochastic function and want to generate new output
* you cancelled the task but want to try again now

You can retry tasks with `task_retry()`, which is easier than submitting a new task with the same content, and also preserves a link between retried tasks.

Our random walk will give slightly different results each time we use it, so we demonstrate the idea with that:


```r
id1 <- task_create_expr(random_walk(0, 10))
#> âœ” Submitted task '758168a1a3eb6045e87553000f4a6266' using 'windows'
task_wait(id1)
#> [1] TRUE
task_result(id1)
#>  [1] -0.265657593 -0.681628235 -0.749935937 -0.668496440 -0.002458436
#>  [6]  0.166539101 -1.910818573 -2.127869873 -1.725634000 -2.196765476
```

Here we ran a random walk and it got to -2.1967655, which is clearly not what we were expecting.  Let's try it again:


```r
id2 <- task_retry(id1)
#> âœ” Submitted task '3f8383545017aca47f11fe937d2b44cb' using 'windows'
```

Running `task_retry` creates a *new* task, with a new id `3f8383...` compared with `758168...`.

Once this task has finished, we get a different result:


```r
task_wait(id2)
#> [1] TRUE
task_result(id2)
#>  [1]  0.9421142  0.9346750 -0.5758553 -0.3701097 -0.8435997 -1.4157393
#>  [7] -2.8674198 -2.7379789 -3.1561416 -3.1945512
```

We get a hint that this is a retried task from the `task_info`


```r
task_info(id2)
#> 
#> â”€â”€ task 3f8383545017aca47f11fe937d2b44cb (success) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#> â„¹ Submitted with 'windows'
#> â„¹ Created at 2024-01-10 10:33:19.810693 (moments ago)
#> â„¹ Started at 2024-01-10 10:33:22.004266 (moments ago; waited 2.2s)
#> â„¹ Finished at 2024-01-10 10:33:22.439971 (moments ago; ran for 436ms)
#> â„¹ Last of a chain of a task retried 1 time
```

You can see the full chain of retries here:


```r
task_info(id2)$chain
#> [1] "758168a1a3eb6045e87553000f4a6266" "3f8383545017aca47f11fe937d2b44cb"
```

Once a task has been retried it affects how you interact with the previous ids; by default they follow through to the most recent element in the chain:


```r
task_result(id1)
#>  [1]  0.9421142  0.9346750 -0.5758553 -0.3701097 -0.8435997 -1.4157393
#>  [7] -2.8674198 -2.7379789 -3.1561416 -3.1945512
task_result(id2)
#>  [1]  0.9421142  0.9346750 -0.5758553 -0.3701097 -0.8435997 -1.4157393
#>  [7] -2.8674198 -2.7379789 -3.1561416 -3.1945512
```

You can get the original result back by using `follow = FALSE`:


```r
task_result(id1, follow = FALSE)
#>  [1] -0.265657593 -0.681628235 -0.749935937 -0.668496440 -0.002458436
#>  [6]  0.166539101 -1.910818573 -2.127869873 -1.725634000 -2.196765476
task_result(id2)
#>  [1]  0.9421142  0.9346750 -0.5758553 -0.3701097 -0.8435997 -1.4157393
#>  [7] -2.8674198 -2.7379789 -3.1561416 -3.1945512
```

Only tasks that have been completed (`success`, `failure` or `cancelled`) can be retried, and doing so adds a new task to the *end* of the chain; there is no branching. Retrying the `id1` here would create the chain `id1 -> id2 -> id3`, and following would select `id3` for any of the three tasks in the chain.

You cannot currently change any property of a retried task, we may change this in future.
