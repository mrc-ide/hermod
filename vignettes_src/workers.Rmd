---
title: "Workers"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Workers}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

<!-- This vignette really requires a real cluster behind it to work
     properly; we're going to submit a bunch of workers and tasks at
     them.  It requires a working redis server too, so is going to be
     hard to get running on CI.  Eventually, it would probably be good
     to get this working with the example driver though as then it's
     more likely to keep working -->


```{r setup, include = FALSE}
source("../vignettes/common.R")
vignette_root <- new_hipercow_root_path(TRUE)
set_vignette_root(vignette_root)
```

```{r, echo = FALSE, results = "asis"}
add_header()
```

This vignette describes a pair of relatively advanced techniques for using a *second* queue embedded on top of the usual HPC scheduler in order to scale work; either running many more tasks than is convenient to run with the HPC scheduler, or running tasks that need more resources than you can easily get on a single cluster node.

If you have thousands and thousands of tasks to submit at once you may not want to flood the cluster with them all at once. Each task submission tends to be relatively slow on every platform that we have used, and submitting thousands of tasks will take minutes (even if you could submit 10 tasks a second, 1000 tasks will take almost two minutes, and a million tasks would take 27 hours!). Some cluster schedulers also slow down as the queue size increases, becoming less efficient at distributing work. And if you take up the whole cluster someone may come and find you in order to complain.  At the same time, batching your tasks up into little bits and manually sending them off is a pain and work better done by a computer.  An alternative is to submit a (relatively small) set of "workers" to the cluster, and then submit tasks to them.  We call this the **"lightweight queue pattern"**.

The second use case is where you want to run some computation on the cluster that needs to run some of its calculations in parallel, as you might do following instructions in `vignette("parallel")`.  Suppose that your cluster only has nodes with 32 cores though, and you have some calculations that would benefit from more cores than this.  Or suppose that you want to farm out some smaller number number of sub-tasks each of which will consume an entire node.  You can use the approach described here to scale your tasks off a single node, and we call this the **"interprocess communication pattern"**.

Both of these patterns are enabled with our [`rrq`](https://mrc-ide.github.io/rrq) package, along with a [Redis](https://redis.io) server which is already running on the cluster.

# Getting started

To get started, you will need the `rrq` package, if you do not have it already (this will be installed automatically by hipercow, you can skip this step if you want)

```r
install.packages(
  "rrq",
  repos = c("https://mrc-ide.r-universe.dev", "https://cloud.r-project.org"))
```

You'll want a very recent verision; here we are using version `r as.character(packageVersion("rrq"))`

```{r}
library(hipercow)
hipercow_init(driver = "example")
```

```{r, include = FALSE}
cleanup <- withr::with_dir(
  vignette_root,
  hipercow::hipercow_example_helper(with_logging = TRUE,
                                    new_directory = FALSE,
                                    initialise = FALSE,
                                    runner = 3))
```

# The lightweight queue pattern

Most interaction with `rrq` is done via a "controller"; this is an object that you can use to submit tasks and query on their status:

```{r}
r <- hipercow_rrq_controller()
```

The interface to this controller is subject to change, but many of the ideas will feel very similar to you from hipercow itself.  The controller object is just a handle that can be used with most functions in the rrq package:

```{r}
r
```

The other thing you'll need are some workers.  Let's submit four workers to the cluster, and wait for them to become available:

```{r}
hipercow_rrq_workers_submit(4)
```

## Basic usage

Submitting a task works much the same as hipercow, except that rather than `task_create_expr` you will use `rrq::rrq_task_create_expr` and pass the the controller as an argument:

```{r}
id <- rrq::rrq_task_create_expr(runif(10), controller = r)
```

as with hipercow, this `id` is a hex string:

```{r}
id
```

There's nothing here to distinguish this from a task identifier in hipercow itself, so be careful with your workflows.

Once you have you have your task, interacting with it will feel familiar as you can query its status, wait on it and fetch the result:

```{r}
rrq::rrq_task_status(id, controller = r)
rrq::rrq_task_wait(id, controller = r)
rrq::rrq_task_result(id, controller = r)
```

The big difference here from hipercow is how fast this process should be; the roundtrip of a task here will be a (hopefully small) fraction of a second:

```{r}
system.time({
  id <- rrq::rrq_task_create_expr(runif(10), controller = r)
  rrq::rrq_task_wait(id, controller = r)
  rrq::rrq_task_result(id, controller = r)
})
```

Passing in the `controller` argument here will possibly be annoying as you'll probably only ever have a single rrq controller, so you can use `rrq::rrq_default_controller_set` to set a default controller and then omit this argument:

```{r}
rrq::rrq_default_controller_set(r)
rrq::rrq_task_status(id)
```

## Scaling up

Let's submit 1,000 trivial tasks, using `rrq::rrq_task_create_bulk_expr`:

```{r, include = FALSE}
t0 <- Sys.time()
```
```{r}
ids <- rrq::rrq_task_create_bulk_expr(sqrt(x), data.frame(x = 1:1000))
```

There's no equivalent of a task bundle in `rrq`; this just returns a vector of task 1000 task identifiers.  You can pass this vector in to `rrq::rrq_task_wait()` though, and then fetch the results using `rrq::rrq_task_results()` (note the pluralisation; `rrq_task_results` always returns a list, while `rrq_task_result` fetches a single task result).

```{r}
ok <- rrq::rrq_task_wait(ids)
result <- rrq::rrq_task_results(ids)
```

```{r, include = FALSE}
t1 <- Sys.time()
elapsed <- round(as.numeric(Sys.time() - (Sys.time() - 20), "secs"), 1)
```

This process has taken `r elapsed` seconds, which is likely much faster than submitting this many tasks directly.

## Permanence

You should not treat data in a submitted task as permanent; it is subject for deletion at any point!  So your aim should be to pull the data out of rrq as soon as you can.  Practically we won't delete data from the database for at least a few days after creation, but we make no guarantees.  We'll describe cleanup here later.

## Controlling the worker

The workers will use the `rrq` environment if it exists, failing that the `default` environment.  So if you need different packages and sources loaded on the workers on your normal tasks, you can do this by creating a different environment

```{r}
hipercow_environment_create("rrq", packages = "cowsay")
```

**TODO**: *work out how to refresh this environment; I think that's just a message to send*

You can submit your workers with any resources and parallel control you want (see `vignettes("parallel")` for details); pass these as `resources` and `parallel` to `hipercow_rrq_workers_submit()`.

# Interprocess commuication pattern

You can submit a task to the cluster that accesses your pool of workers.  Here we have four workers already running in the previous example, and we already know how to distribute work over them.

The example here is contrived but contains all the ingredients needed to do a map-reduce style task, where you submit a task to the cluster and that task distributes subtasks across a pool of workers, performs some reduction on them, and returns.

```{r, include = FALSE}
code <- c(
  "example <- function(n) {",
  "  ids <- rrq:rrq_task_create_bulk_call(sqrt, seq_len(n))",
  "  ok <- rrq::rrq_task_wait(ids)",
  "  stopifnot(ok)",
  "  result <- rrq::rrq_task_results(ids)",
  "  rrq::rrq_task_delete(ids)",
  "  sum(unlist(result))",
  "}")
writeLines(code, "code.R")
```

```{r, echo = FALSE, results = "asis"}
writeLines("code.R")
```

There are several important points here:

* You do not need to use `controller` argument to any of the rrq functions; if you submit this task with the appropriate `parallel` argument (see below) the default controller will be configured for you
* We delete the tasks as soon as we collect their results

Save this in our default environment:

```{r}
hipercow_environment_create("default", sources = "code.R")
```

now submit a task that will call this function:

```{r}
id <- task_create_expr(example(16), parallel = hipercow_parallel(use_rrq = TRUE))
id
```

Here, `id` is a *hipercow* task identifier.  This sends an additional task to the queue, so now we have five things running on the cluster (four workers and one task).  The task runs, picks up the controller, then uses it do distribute a (trivial) calculation over the four workers.

```{r}
task_wait(id)
task_result(id)
```

You can see from the worker logs here the tasks being split between the workers:

```{r}
rrq::rrq_worker_log_tail(n = 32)
```

This example is trivial, but you could submit 10 workers each using a 32 core node, and then use a single core task to farm out a series of large simulations across your bank of computers.  Or create a 500 single core workers (so ~25% of the cluster) and smash through a huge number of simulations with minimal overhead.
