##' Create an rrq controller for your queue.  Use this to interact
##' with workers created with [hipercow_rrq_workers_submit()].  Proper
##' docs forthcoming, all interfaces are subject to some change.
##'
##' @title Create an rrq controller
##'
##' @param ... Additional arguments passed through to the
##'   `rrq_controller` constructor; currently this is `follow` and
##'   `timeout_task_wait`.
##'
##' @param driver Name of the driver to use.  The default (`NULL`)
##'   depends on your configured drivers; if you have no drivers
##'   configured we will error as we lack information required to
##'   proceed.  If you have exactly one driver configured we'll submit
##'   your task with it.  If you have more than one driver configured,
##'   then we will error, though in future versions we may fall back
##'   on a default driver if you have one configured.
##'
##' @inheritParams task_create_expr
##'
##' @return An [rrq::rrq_controller] object, with many methods.  See
##'   the [rrq docs](https://mrc-ide.github.io/) for information on
##'   using this.
##'
##' @export
hipercow_rrq_controller <- function(..., driver = NULL, root = NULL) {
  root <- hipercow_root(root)
  ## Downside of this approach is it's hard to write something that
  ## will allow connection to a queue from a process that allows
  ## connecting to an existing one.  We should switch here based on an
  ## environment variable I think, and require that the driver task
  ## sets something sensible, perhaps the current task that they are
  ## working on?
  driver <- hipercow_driver_select(driver, TRUE, root, rlang::current_env())
  rrq_prepare(driver, root, ..., call = rlang::current_env())
}


##' Submit workers to the cluster, use this in conjunction with
##' [hipercow_rrq_controller].  A worker may sit on a single core or a
##' whole node depending on how you set up `resources`.  We use the
##' `rrq` environment if it exists ([hipercow_environment_create])
##' otherwise we'll use the `default` environment.
##'
##' @title Submit rrq workers
##'
##' @param n The number of workers to submit. This is the only
##'   required argument.
##'
##' @inheritParams hipercow_rrq_controller
##'
##' @param resources A list generated by [hipercow_resources] giving
##'   the cluster resource requirements to run your task.
##'
##' @param envvars Environment variables as generated by
##'   [hipercow_envvars], which you might use to control your task.
##'
##' @param parallel Parallel configuration as generated by
##'   [hipercow_parallel], which defines which method, if any, will be
##'   used to initialise your worker for parallel execution (which
##'   means you have to think about parallelism at three levels at
##'   least, a diagram may help here).
##'
##' @param timeout Time to wait for workers to appear.
##'
##' @param progress Should we display a progress bar?
##'
##' @inheritParams task_eval
##'
##' @return A vector of worker ids
##' @export
hipercow_rrq_workers_submit <- function(n,
                                        driver = NULL, resources = NULL,
                                        envvars = NULL, parallel = NULL,
                                        timeout = NULL, progress = NULL,
                                        root = NULL) {
  root <- hipercow_root(root)
  assert_scalar_integer(n, call = rlang::current_env())

  driver <- hipercow_driver_select(driver, TRUE, root, rlang::current_env())

  r <- rrq_prepare(driver, root, call = rlang::current_env())

  resources <- resources_validate(resources, driver, root)
  envvars <- prepare_envvars(envvars, driver, root, rlang::current_env())
  progress <- show_progress(progress, rlang::current_env())
  timeout <- timeout_value(timeout, rlang::current_env())

  path <- relative_workdir(root$path$root)
  if (path != ".") {
    cli::cli_alert_warning(paste(
      "Your path relative to the root is '{path}', but your workers will",
      "start at the root path; this may or may not be what you are expecting"))
  }

  queue_id <- r$queue_id
  ids <- vapply(seq_len(n), FUN.VALUE = character(2), function(i) {
    worker_id <- sprintf("rrq-%s-%s",
                         sub("^rrq:", "", queue_id),
                         ids::random_id(bytes = 6))
    expr <- rlang::expr({
      rrq::rrq_worker$new(!!queue_id, worker_id = !!worker_id)$loop()
    })
    id <- task_create(root, "expression", ".", "empty", envvars, parallel,
                      expr = expr)
    c(id, worker_id)
  })
  task_ids <- ids[1, ]
  worker_ids <- ids[2, ]

  ## I think that there's a way of getting the logs here to work with
  ## rrq nicely, by setting the path to the workers properly.  I'm not
  ## relaly sure how this is meant to work in practice though.
  path_workers <- file.path(root$path$rrq, "workers", driver)
  fs::dir_create(dirname(path_workers))
  append_lines(worker_ids, path_workers)

  key_alive <- rrq::rrq_worker_expect(r, worker_ids)
  ## Going fine to here, failing with "can't create environment with
  ## special name empty"
  task_submit(task_ids, resources = resources, driver = driver, root = root)
  rrq::rrq_worker_wait(r, key_alive, timeout = timeout, progress = progress)
}


rrq_prepare <- function(driver, root, ..., call = NULL) {
  ensure_package("rrq")
  ensure_package("redux")
  driver <- hipercow_driver_select(driver, TRUE, root, call)
  info <- cluster_info(driver, root)
  if (is.null(info$redis_url)) {
    cli::cli_abort("No redis support for '{driver}'")
  }
  con <- redux::hiredis(url = info$redis_url)
  path_id <- file.path(root$path$rrq, "id", driver)
  if (file.exists(path_id)) {
    queue_id <- readLines(path_id)
    cli::cli_alert_success("Using existing rrq queue '{queue_id}'")
    return(rrq::rrq_controller$new(queue_id, con, ...))
  }

  queue_id <- paste0("rrq:", ids::random_id(bytes = 4))

  ## TODO: Some hard coding here that needs a bit of work, though
  ## practically these can all be worked around after initialisation
  ## easily enough.
  store_max_size <- 100000 # 100k
  timeout_idle <- 300 # 5 minutes
  heartbeat_period <- 60 # one minute

  ## makes thinking about offload path much easier:
  withr::local_dir(root$path$root)
  offload_path <- file.path(root$path$rrq, "offload")
  rrq::rrq_configure(queue_id, con,
                     store_max_size = store_max_size,
                     offload_path = offload_path)

  r <- rrq::rrq_controller$new(queue_id, con, ...)

  cfg <- rrq::rrq_worker_config(timeout_idle = timeout_idle,
                                heartbeat_period = heartbeat_period)
  r$worker_config_save("localhost", cfg)

  r$envir(function(e) {
    nm <- if (hipercow_environment_exists("rrq")) "rrq" else "default"
    data <- environment_load(nm)
    for (p in data$packages) {
      library(p, character.only = TRUE)
    }
    for (s in data$sources) {
      sys.source(s, envir = envir)
    }
  }, notify = FALSE)
  fs::dir_create(dirname(path_id))
  cli::cli_alert_success("Created new rrq queue '{queue_id}'")
  writeLines(queue_id, path_id)
  r
}
