##' Create an rrq controller for your queue.  Use this to interact
##' with workers created with [hipercow_rrq_workers_submit()].  Proper
##' docs forthcoming, all interfaces are subject to some change.
##'
##' If you are going to do much with the controller after creation,
##' you probably want to run `rrq::rrq_default_controller_set()` with
##' the return value of this function, as this will mean that you do
##' not have to add the `controller` argument to all other rrq
##' functions.
##'
##' @title Create an rrq controller
##'
##' @param ... Additional arguments passed through to
##'   [rrq::rrq_controller2()]; currently this is `follow` and
##'   `timeout_task_wait`.
##'
##' @param driver Name of the driver to use.  The default (`NULL`)
##'   depends on your configured drivers; if you have no drivers
##'   configured we will error as we lack information required to
##'   proceed.  If you have exactly one driver configured we'll submit
##'   your task with it.  If you have more than one driver configured,
##'   then we will error, though in future versions we may fall back
##'   on a default driver if you have one configured.
##'
##' @inheritParams task_create_expr
##'
##' @return An [rrq::rrq_controller2] object.
##'
##' @export
hipercow_rrq_controller <- function(..., driver = NULL, root = NULL) {
  root <- hipercow_root(root)
  queue_id <- Sys.getenv("HIPERCOW_RRQ_QUEUE_ID", NA_character_)
  call <- rlang::current_env()
  if (is.na(queue_id)) {
    driver <- hipercow_driver_select(driver, TRUE, root, call)
    rrq_prepare(driver, root, ..., call = call)
  } else {
    cli::cli_alert_success("Connecting to rrq queue '{queue_id}' from task")
    rrq::rrq_controller2(queue_id, con = redux::hiredis(), ...)
  }
}


##' Submit workers to the cluster, use this in conjunction with
##' [hipercow_rrq_controller].  A worker may sit on a single core or a
##' whole node depending on how you set up `resources`.  We use the
##' `rrq` environment if it exists ([hipercow_environment_create])
##' otherwise we'll use the `default` environment.
##'
##' @title Submit rrq workers
##'
##' @param n The number of workers to submit. This is the only
##'   required argument.
##'
##' @inheritParams hipercow_rrq_controller
##'
##' @param resources A list generated by [hipercow_resources] giving
##'   the cluster resource requirements to run your task.
##'
##' @param envvars Environment variables as generated by
##'   [hipercow_envvars], which you might use to control your task.
##'
##' @param parallel Parallel configuration as generated by
##'   [hipercow_parallel], which defines which method, if any, will be
##'   used to initialise your worker for parallel execution (which
##'   means you have to think about parallelism at three levels at
##'   least, a diagram may help here).
##'
##' @param timeout Time to wait for workers to appear.
##'
##' @param progress Should we display a progress bar?
##'
##' @inheritParams task_eval
##'
##' @return A vector of worker ids
##' @export
hipercow_rrq_workers_submit <- function(n,
                                        driver = NULL, resources = NULL,
                                        envvars = NULL, parallel = NULL,
                                        timeout = NULL, progress = NULL,
                                        root = NULL) {
  root <- hipercow_root(root)
  call <- rlang::current_env()
  assert_scalar_integer(n, call = call)

  driver <- hipercow_driver_select(driver, TRUE, root, call)
  r <- rrq_prepare(driver, root, call = call)

  resources <- resources_validate(resources, driver, root)
  envvars <- prepare_envvars(envvars, driver, root, call)
  progress <- show_progress(progress, call)
  timeout <- timeout_value(timeout, call)

  path <- relative_workdir(root$path$root)
  if (path != ".") {
    cli::cli_alert_warning(paste(
      "Your path relative to the root is '{path}', but your workers will",
      "start at the root path; this may or may not be what you are expecting,",
      "and it may not be something you can mitigate until we make some",
      "changes in rrq"))
  }

  queue_id <- r$queue_id
  ids <- vapply(seq_len(n), FUN.VALUE = character(2), function(i) {
    worker_id <- sprintf("rrq-%s-%s",
                         sub("^rrq:", "", queue_id),
                         ids::random_id(bytes = 6))
    expr <- rlang::expr({
      withr::local_envvar("HIPERCOW_RRQ_QUEUE_ID" = !!queue_id)
      rrq::rrq_worker$new(!!queue_id, worker_id = !!worker_id)$loop()
    })
    id <- task_create(root, "expression", ".", "empty", envvars, parallel,
                      expr = expr)
    c(id, worker_id)
  })
  task_ids <- ids[1, ]
  worker_ids <- ids[2, ]

  key_alive <- rrq::rrq_worker_expect2(worker_ids, controller = r)
  task_submit(task_ids, resources = resources, driver = driver, root = root)

  rrq::rrq_worker_wait2(key_alive, timeout = timeout, progress = progress,
                        controller = r)
}


rrq_prepare <- function(driver, root, ..., call = NULL) {
  ensure_package("rrq")
  ensure_package("redux")
  driver <- hipercow_driver_select(driver, TRUE, root, call)
  info <- cluster_info(driver, root)
  if (is.null(info$redis_url)) {
    cli::cli_abort("No redis support for '{driver}'")
  }
  con <- redux::hiredis(url = info$redis_url)
  path_queue_id <- file.path(root$path$rrq, driver)
  if (file.exists(path_queue_id)) {
    queue_id <- readLines(path_queue_id)
    cli::cli_alert_success("Using existing rrq queue '{queue_id}'")
    return(rrq::rrq_controller2(queue_id, con, ...))
  }

  queue_id <- paste0("rrq:", ids::random_id(bytes = 4))

  ## TODO: Some hard coding here that needs a bit of work, though
  ## practically these can all be worked around after initialisation
  ## easily enough, exceppt for store_max_size, which is fixed, I
  ## think (at least for now).
  store_max_size <- 100000 # 100k
  timeout_idle <- 300 # 5 minutes
  heartbeat_period <- 60 # one minute

  ## We can't _generally_ use an offload like this, though we can with
  ## the windows cluster.  This is something we'll have to think about
  ## fairly carefully, and it might be worth holding off until we have
  ## the linux cluster working properly, really.  We could switch this
  ## on for the windows and example driver and nothing else perhaps,
  ## but probably best if that is within the cluster info I think so
  ## we can look it up.
  withr::local_dir(root$path$root)
  offload_path <- file.path(root$path$rrq, "offload")
  rrq::rrq_configure(queue_id, con,
                     store_max_size = store_max_size,
                     offload_path = offload_path)

  r <- rrq::rrq_controller2(queue_id, con, ...)

  cfg <- rrq::rrq_worker_config(timeout_idle = timeout_idle,
                                heartbeat_period = heartbeat_period,
                                verbose = FALSE)
  rrq::rrq_worker_config_save(queue_id, "localhost", cfg, con = con)

  ## We're going to hit the same issues here with making sure that any
  ## remote worker can read paths as we have with submitting general
  ## tasks; this will be easiest to think about once we have the ssh
  ## drivers all working.
  rrq::rrq_worker_envir_set(function(e) {
    nm <- if (hipercow_environment_exists("rrq")) "rrq" else "default"
    data <- environment_load(nm)
    for (p in data$packages) {
      library(p, character.only = TRUE)
    }
    for (s in data$sources) {
      sys.source(s, envir = envir)
    }
  }, notify = FALSE, controller = r)
  fs::dir_create(dirname(path_queue_id))
  cli::cli_alert_success("Created new rrq queue '{queue_id}'")
  writeLines(queue_id, path_queue_id)
  r
}
